# 进程

## 概念

程序是一堆冰冷的代码，而代码载入内存、执行起来就可以被称作进程。进程是操作系统分配内存、CPU时间等资源的独立单位。

- 组成
  - PCB：存储进程运行时的状态信息，如程序计数器、寄存器、打开文件列表等，便于系统的调度。
  - 程序段（同一个代码段可以被多个进程共享）
  - 数据段
  
- 状态

  ![image-20221031200549334](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20221031200549334.png)

  - 创建(new)：进程正在被创建
  - 运行(running)
  - 等待(waiting)：进程等待发生某个事件，如I/O
  - 就绪(ready)：进程等待被分配处理器
  - 终止(terminated)

## PCB

Process control block，进程控制块，包含某个进程的如下信息：

- 描述信息，包括进程标识符、父进程标识符、用户标识符
- 进程状态，也就是创建、运行、等待、就绪、终止等
- 程序计数器
- CPU寄存器
- CPU调度信息：进程优先级、调度队列的指针等
- 资源分配信息：打开的文件、I/O设备列表，虚拟地址空间信息
- 统计信息：如CPU使用时间

## 控制

- 调度队列：PCB以链表的方式存储，构成就绪队列、某个I/O设备的等待队列等。当然也有用数组存储的方式。

- 进程得到执行后可能会发生如下事件：

  - 发起I/O请求，则将其移入I/O等待队列
  - 创建子进程
  - 被中断，则移入就绪队列
  - 运行结束，则释放PCB和其他资源

- 调度程序有两种：

  - 长期调度程序(long-term scheduler)或作业调度程序(job scheduler)选择哪些进程准备被CPU轮转执行，也就是控制多道程序程度(degree of multiprogramming)。
  - 短期调度程序(short-term scheduler)或CPU调度程序(CPU scheduler)选择将CPU分配给长期调度程序选择出的待运行程序中的哪一个。
  - 有的操作系统中还存在将程序移出CPU竞争以降低多道程序程度的中期调度程序(medium-term scheduler)。

  有的操作系统只有短期调度程序，如Windows，则可能会使性能被分摊到低至无法忍受。

- 上下文切换：将当前进程的信息保存到PCB，移动PCB到就绪、I/O等队列，然后将新进程的PCB中的信息恢复到CPU。

- 进程创建：由父进程创建一个子进程，属性包括：

  - 资源是继承父进程还是单独从操作系统分配
  - 父进程是与子进程并行执行，还是等待子进程运行结束后再继续
  - 子进程是复制父进程的地址空间，还是加载一个新程序

- 进程终止：进程运行结束，或父进程、操作系统等强制终止该进程时释放该进程的资源、删除其PCB。有的系统要求父进程终止后其子进程也必须终止（级联终止，cascade termination）

## 通信

操作系统的中的不同进程之间需要协作，好处包括信息共享、并行计算加速、模块化、方便用户并行执行多个任务。为此操作系统需要提供进程间通信(IPC, Interprocess Communication)的机制。

- 对于运行在本地的进程之间的通信，有以下两种模型：
  - 共享内存(shared memory)，要考虑缓冲区是否有界，以及缓冲区的互斥访问等问题。
  - 消息传递(message passing)，要考虑是直接通信(direct communication，通信者直接通过进程名与对方联系)还是间接通信(indirect communication，通过邮箱或端口发送信息)，以及发送方和接收方是否阻塞(blocking)，以及消息队列的容量大小(零容量，有限容量，无限容量)等问题。
- 对于客户机/服务器系统之间的通信，包括以下三种方式：
  - 套接字(socket)
  - 远程过程调用(RPC, Remote Procedure Call)
  - 管道(pipe)

# 线程

线程是在进程的基础上对计算机资源进行进一步的划分。对于进程而言，每个进程仿佛独占一台计算机。而对于同一进程下的不同线程而言，他们仅仅独占CPU和运行堆栈，代码、数据、文件等资源都是共享的。

![image-20221030110820653](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20221030110820653.png)

- 内核线程(kernel thread)：由操作系统直接支持和管理，所有的内核线程管理工作都在内核态进行。
- 用户线程(user thread)：基于内核线程实现，用户线程的管理无需内核支持。

## 多线程模型

![img](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/398159-20151005113721456-889440721.jpg)

- 多对一模型：多个用户线程映射到一个内核线程，这种方式下内核管理无需进入内核态，效率较高，但当某个线程在内核态阻塞时，整个进程都会被阻塞。
- 一对一模型：提供了较好的并发性，但由于内核进程的创建和切换会浪费资源，该方法效率较低。
- 多对多模型：允许将多个用户级线程多路复用到同样数量或更少数量的内核进程，以同时满足并发性和效率。
- 双层模型：在多对多模型的基础上增加了将某个用户线程绑定到内核进程的支持。

## 线程库

线程库(thread library)为程序员提供创建和管理线程的API。线程库的实现包括：

- 用户级：库的代码和数据结构位于用户空间，调用库函数不会进入内核。
- 内核级：库的代码和数据结构位于内核空间，调用库函数通常会导致内核的系统调用。

## LWP

LWP(LightWeight Process)，轻量级线程，是多对多和双层模型中使用的一种数据结构。与线程(用户线程实现的多对一结构)相比，LWP拥有独立的进程ID，可以由内核直接调度。与进程相比，LWP之间可以共享地址空间、打开文件等资源。

- 起初，Linux下内核只提供了对进程(独立地址空间)的支持，想要实现线程需要线程库基于单个进程上模拟出多个线程。这种方式的问题在于当某个线程进入阻碍，内核并不知情，因此只能保持该进程的运行，造成卡死。
- 然后Linux增加了进程之间共享地址空间、打开文件等资源的能力，线程库就可以基于进程来模拟线程了。通过直接将用户线程绑定到内核进程上，内核就可以直接操控用户线程了。这样的进程就被称作LWP。

## 隐式多线程

为简化多线程程序的设计，可以将多线程的创建和管理交给编译器和运行时库完成，即隐式线程(implicit threading)。以下是三种隐式线程的实现：

- 线程池(thread pool)：在进程开始时就创建一定数量的线程，随用随取。这种办法节省了需要时再创建线程的时间，也控制了线程的最大数量。
- OpenMP：提供一组编译指令和API，使得程序员只需要在程序中用编译指令标识出需要并行执行的代码段，编译器就会自行实现。
- 大中央调度(Grand Central Dispatch, GCD)：与OpenMP类似，程序员用块标记需要并行执行的代码段，并将块添加到调度队列(dispatchqueue)，GCD自动完成将代码块移出队列、为块分配线程池中的线程、动态调整线程池大小的工作。

## 多线程问题

- fork函数可以选择是复制进程下的所有线程，还是只复制调用fork的线程。
- 调用exec函数时会用参数指定的程序取代整个进程，包括进程下的所有线程。
- 线程撤销(thread cancellation)：线程还未运行结束就提前结束运行。包括异步撤销和同步撤销两种方式，异步撤销时线程立即终止，延迟撤销时线程自己检查是否需要终止。
- 线程的本地存储(Thread-Local Storage, TLS)：线程间虽然共享数据，但也可以拥有自己单独的存储区域。

# 调度

## 概念

- 需要调度的情形包括四种：
  - 进程主动等待，如等待I/O、调用wait()
  - 进程终止
  - 进程被迫结束，如出现中断
  - 进程等待的事件完成，如I/O完成

- 不可以进行调度的情形包括三种：
  - 某些不可以被打断的中断程序
  - 处于操作系统内核临界区中时
  - 执行原子操作时

- 调度方式：分为非抢占的(nonpreemptive, 也称协作的, cooperative)和抢占的(preemptive)
  - 非抢占的：除非进程主动停止，否则该进程会保持执行
  - 抢占的：当优先级更高的事件出现时，正在执行的进程立刻让出CPU

- 调度程序(dispatcher)：用于将CPU切换给短期调度程序选择的进程，工作包括保存原进程信息、恢复新进程信息

- 表示方式：甘特图(Gantt chart)

  ![image-20221031201149423](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20221031201149423.png)

## 指标

- CPU使用率：越高越好
- 吞吐量(throughput)：单位时间内完成的进程的数量
- 周转时间(turnaround time)：某个进程从提交到执行完毕所需的总时间，包括等待进入内存、等待CPU、等待I/O、实际执行等。
- 等待时间：进程在就绪队列中等待的总时间
- 响应时间：从用户提交请求到系统首次相应的时间，如计算多个数据并输出时，输出第一个数据的时间是响应时间，全部输出完成的时间是周转时间

## 进程调度算法

- 先到先服务(First-Come First-Served, FIFS)，可能由于某个进程占用的时间过长导致其他进程等待时间过长
- 最短作业优先(Shortest-Job-First, SJF)，即最短下次CPU执行时间优先(shortest-next-CPU-ubrst)

  - 新到达的进程所需的时间可能比正在被执行进程的剩余时间还短，允许正在被运行的进程被抢占的算法也称作最短剩余时间优先(shortest-remaining-time-first)

  - 实际情况中无法得知进程的下次CPU执行时间。解决方法包括：

    - 预测CPU执行时间，方法是按下面的公式来计算指数平均(exponential average)。设 $t_n$ 为第 $n$ 个 CPU 执行长度, 设 $\tau_{n+1}$ 为下次 CPU 执行预测值。对于 $\alpha$，$0 \leqslant \alpha \leqslant 1$，定义$\tau_{n+1}=\alpha t_n+(1-\alpha) \tau_n$
    - 用户给出预估时间，长期调度程序根据这个时间进行SJF调度
- 优先级调度(priority-scheduling)，根据进程的时限、内存要求、平均CPU执行时间、I/O数量和时间、执行任务的重要程度等因素综合得到一个优先级。为防止低优先级进程饥饿(starvation)，可以采用老化(aging)的方法，进程每等待一段时间就提高它的优先级。
- 轮转(Round-Robin, RR)，CPU循环整个就绪队列，每个进程最多执行一个时间量(time quantum, 或时间片, time slice)的长度，然后就会被抢占，执行队列中的下一个进程。这种方法平均等待时间长，上下文切换也会浪费很多时间。
- 多级队列(multilevel queue)：根据进程的属性将其分为不同队列，每个队列内部使用不同的调度算法，不同队列之间采用优先级抢占调度。如：前台进程采用RR，后台进程采用FCFS，前台进程队列优先于后台进程队列。
- 多级反馈队列调度(multilevel feedback queue)，允许进程在队列之间动态迁移，如进程首先进入短时间片高优先级的队列，一个时间片内没有执行完则移入长时间片低优先级的队列。

## 线程调度

- 进程竞争范围(Process-Contention Scope, PCS)：决定同一进程下的哪一个线程分配给内核线程
- 系统竞争范围(System-Contention Scope, SCS)：决定哪一个内核线程分配给物理CPU

## 多处理器调度

两个概念的区别：

- 并行(parallelism)：多个任务同时执行。
- 并发(concurrency)：多个任务看上去都在取得进展。实际上取得这种效果并不一定要求这些任务同时执行，轮流执行也可以做到。

多处理器调度下要考虑的问题：

- 非对称多处理(asymmetric multiprocessing)和对称多处理(Symmetric Multiprocessing, SMP)：是由某个核集中处理所有调度、I/O等系统活动，还是每个核分别独立的进行调度。
- 处理器亲和性(processor affinity)：将进程从一个核迁移到另一个核代价太大，缓存结构也会丢失，因此最好不要将进程在不同核之间迁移。包括尽力而为的软亲和性、以及由底层提供保证的硬亲和性。
- 负载均衡(load balance)：存在推迁移(push migration)，忙碌核上的进程被强制性推到空闲核上，以及拉迁移(pull migration)，空闲的核自己从忙碌的核中拉取进程。

## 实时CPU调度

对于有较高实时性要求的进程调度系统，存在软实时系统(soft real-time system)和硬实时系统(hard real-time systemm)两种实现。软实时系统仅仅保证关键进程的优先执行，而硬实时系统则进一步要求进程在其截止时间前执行完毕。

- 单调速率(rate-monotonic)调度算法：抢占式，周期短的进程优先级高
- 最早截止期限优先(Earliest-Deadline-First, EDF)：抢占式，截止时间早的进程优先级高

# 同步

临界区(critical section)，表示一个不允许多个进程同时进入的代码段。为实现互斥、高效率，临界区问题的解决方案应满足：

- 空闲让进：临界区空闲时应该允许一个请求进入的进程立即进入
- 忙则等待：已经有进程进入临界区时，其他试图进入的进程应该等待
- 有限等待：进程等待的过程中，其他进程进入临界区的次数是有限的
- 让权等待：进程发现无法进入临界区时应释放处理器

## Peterson解决方案

两个进程竞争临界区的软件解决方案。两个进程共享：

```c++
int turn;//表示哪个进程能进入
bool flag[2];//表示每个进程是否准备进入临界区
```

每个进程的结构为：

```c++
do{
	flag[i] = true;//表明意愿
	turn = j;//谦让
	while(flag[j] && turn == j);//对方不想进入，或对方想进入但谦让了，才能进入临界区
	/*临界区*/
	flag[i] = false;
	/*剩余区*/
}
```

## 硬件同步

由硬件提供对互斥的支持，包括对于单核处理器的直接在临界区执行时禁用中断的方法，以及提供特殊的原子指令(atomic instruction，不可中断的指令)的方法。两种这样的原子指令如下：

- test_and_set：定义和互斥实现分别为

  ```c++
  bool test_and_set(bool *target)
  {
  	bool rv = *target;//保存返回值
  	*target = true;//尝试加锁
  	return rv;//返回false表示完成了加锁动作，true表示锁本来就是锁定状态
  }
  ```

  ```c++
  do{
  	while(test_and_set(&lock));//尝试上锁
  	/*临界区*/
  	lock = false;//解锁
  	/*剩余区*/
  }while(true);
  ```

- compare_and_swap：定义和实现分别为

  ```c++
  int compare_and_swap(int *value, int expected, int new_value)
  {
  	int temp = *value;
  	if(*value == expected)
  		*value = new_value;
  	return temp;
  }
  ```

  ```c++
  do{
  	while(compare_and_swap(&lock, 0, 1) != 0);//等待
  	/*临界区*/
  	lock = 0;
  	/*剩余区*/
  }while(true);
  ```

## 互斥锁

- acquire()
- release()

## 信号量

- wait()（P）
- signal()（V）

## 存在的问题

- 死锁
- 优先级反转，解决方式是优先级继承协议

## 经典同步问题

- 有界缓冲问题
- 读者-作者问题
- 哲学家就餐问题

## 管程

管程(monitor)是一种封装后的同步工具，管程确保每次只有一个进程在管程内处于活动状态。同时管程还提供了条件(condition)变量，每个条件变量都有wait()和signal()两种操作。

# 死锁

实际中操作系统对于死锁均采取了忽视的态度，不对死锁做任何预防和处理，将问题完全交由开发者解决。

## 产生原因

以下四个条件同时满足则会产生死锁：

- 互斥(mutual exclusion)：至少一个资源的访问是互斥的。
- 占有并等待(hold and wait)：某个进程占有至少一个资源，同时等待其他进程占有的另一个资源。
- 非抢占(no preemption)：资源被占有后无法被抢占，除非进程主动释放。
- 循环等待(circular wait)：出现了等待资源的循环，即进程$P_0$等待$P_1$所占有的资源，$P_1$等待$P_2$所占有的资源，$P2$等待$P_3$，……，$P_n$等待$P_0$。

## 预防

通过破坏死锁的产生条件，从根本上防止死锁的出现。

- 防止互斥，即允许资源的共享访问。
- 防止占有并等待，实现方式包括要求进程一次性申请完所有所需的资源，以及要求进程申请资源时不能拥有其他资源。
- 允许抢占，即当进程等待时，允许它已拥有的资源被其他进程抢占。
- 防止循环等待：为每一个资源分配一个唯一的整数，进程只能按递增顺序申请资源，如当进程拥有资源3时，它只能申请序号大于3的资源，想要申请小于3的资源必须释放掉大于等于3的资源。

## 避免

程序运行过程中动态确认，避免进入可能造成死锁的情况。这些算法要求进程提前给出可能会用到的最大资源数量。

- 安全状态：至少存在一种执行顺序，使得进程序列能够以最大需求量顺利执行，且不造成死锁。即存在一个进程执行序列$P_{1},P_{2},P_{3},...P_{n}$，轮到$P_{i}$执行时，它所需要的最大资源数小于它前面执行的所有进程将资源全部释放后系统剩余的资源数。

- 资源分配图：圆形表示进程，矩形表示资源，资源的多个实例用圆点表示。资源指向进程表示资源的分配，进程指向资源表示对资源的申请。当每个资源都只有一个实例时，图中有环表示可能出现死锁。

  资源分配图算法：在资源分配图的基础上，用虚线表示可能的需求，当进程要申请某个资源时判断假如真的分配，资源分配图会不会成环，如果不会才能成功申请。

  ![image-20221031102103940](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20221031102103940.png)

- 银行家算法：包括判断某个状态是否安全的算法，以及判断是否要允许某个请求的算法两部分：

  - 判断系统是否处于安全状态：假设某个进程所需的最大资源数为$\vec{a}$，当前已经占有的资源数为$\vec{b}$，则这个进程当前最多还可以申请的资源数为$\vec{a}-\vec{b}$。（1）寻找当前系统剩余的资源数是否还满足某个进程最多还需要的资源数，如果有则假设这个进程执行完了，释放掉它的全部资源。（2）重复（1），直至所有进程都执行完了，说明状态安全。（3）如果不能像这样执行完所有进程，则说明当前状态不安全。
  - 判断是否允许某个资源请求：对于某个进程的资源请求$\vec{r}$，只有当该请求小于$\vec{a}-\vec{b}$，且系统资源减少$\vec{r}$后仍处于安全状态，该请求才可以被允许。

## 检测

![image-20221031092243445](media/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20221031092243445.png)

- 利用资源分配图：资源分配图成环时表示出现死锁。
- 利用等待图：如果进程$P_i$等待资源$R$，而$R$被进程$P_j$占有，则称$P_i$等待$P_j$。等待图中进程$P_i$指向进程$P_j$表示$P_i$等待$P_j$。等待图中有环表示可能出现死锁。
- 利用资源分配图和等待图进行检测的方法不适用于每个资源有多个实例的情况，此时可以用类似银行家算法的方法，若对于某个系统：剩余资源、每个进程的已占有资源、每个进程正在请求的资源不满足安全条件，证明出现了死锁。与银行家算法的对比是，银行家算法中假定每个进程即将申请的资源数为最大的需求量减去已占有的，而这里使用的是实际的申请数量，不需要用到进程可能用到的最大资源数。

## 恢复

从死锁中恢复的方法包括：

- 终止进程：包括一次性终止所有死锁进程并收回资源，以及一次终止一个死锁进程知直到死锁状态解除为止。
- 资源抢占：挂起某些死锁进程，让出它们所占有的资源。
- 回滚：将一个或多个进程回滚到能解开死锁的程度，这要求进程的历史信息得到记录。

这些恢复策略需要考虑到公平性，要根据进程的优先级、执行时间、占有的资源数目等因素选择牺牲哪些进程，同时还要避免某些进程饥饿。
