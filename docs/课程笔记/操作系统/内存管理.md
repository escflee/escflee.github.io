# 地址转换

如果程序在编译时就已经知道了程序将会处在内存中的什么位置，那么直接在程序中写入实际内存的地址就可以了。而实际上这是不可能的，在多进程系统中程序每次执行时在内存中所处的位置都可能不一样。考虑到进程会被挂起、重启的情况，程序所处的地址甚至还会在运行途中发生变化。

因此，可以在编译程序时不把地址写死，而是在加载程序时，或运行程序时再计算实际地址。

## 逻辑地址，物理地址

CPU生成的地址称为逻辑地址(logical address)，而内存单元看到的地址称为物理地址(physical address)。

## MMU

虚拟地址到逻辑地址的映射是由硬件完成的，称该部件为内存管理单元(Memory-Management Unit, MMU)。根据实际的内存分配方式不同，MMU的结构也不同，

一种最简单的内存分配方式是，为每个进程分配一块连续的空间，MMU用重定位寄存器(relocation register)存储进程的开始地址，程序中的逻辑地址为相对地址，MMU只需要将逻辑地址与开始地址相加就能得到物理地址。

# 内存分配

在介绍实际的内存分配方式之前，先解决一些内存分配中的基本问题，它们是连续内存分配、分段、分页、虚拟内存等内存分配方式的基础。

## 分区方式

按什么方式来将内存进行分区，方法包括：

- 固定大小分区
- 可变分区(variable-partition)：分区大小不固定，操作系统记录哪些位置空闲(孔, hole)，哪些位置已用。

## 分配方式

当新进程需要内存时，选择将哪个孔分配给它的办法，包括：

- 首次适应(first-fit)：分配首个足够大的孔
- 最优适应(best-fit)：分配最小的足够大的孔，目的在于使碎片最小。
- 最差适应(worst-fit)：分配最大的孔，目的在于使碎片尽可能可用。

## 碎片

总的可用空间连续，但因过于分裂而无法使用的情况就是碎片。碎片包括：

- 内部碎片(internal fragmentation)：分配给了进程，但进程用不上的空间。
- 外部碎片(external fragmentation)：没有分配给进程，但无法使用的空间。

解决碎片的方法包括：

- 紧缩(compaction)：移动已有的内容，以整合碎片。
- 允许进程使用多个不连续的空间，如分段、分页。

## 交换

程序必须在内存中才可以运行，但可以暂时将程序数据移入磁盘以腾出内存空间，需要的时候再取回，以提升系统的多道程序程度。需要注意的问题包括：

- 正在等待I/O或其他事件的进程不应该被移出。
- 频繁的交换可能造成磁盘的过度损耗。
- 交换非常耗时，应该在必要时才使用，同时可以采用只交换部分数据的方式提高效率。

# 连续内存分配

contiguous memory allocation，为每个进程分配的空间都是连续的，是一种非常初级的分配方式，但可以解决内存保护和地址绑定的问题。

## 地址转换

代码中的地址均为相对地址，由MMU在运行时添加上起始地址得到物理地址。

![image-20221121195212025](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121195212025.png)

## 内存保护

为了防止进程访问到不属于自己的空间，可以使用界限寄存器、重定位寄存器分别记录进程内存的长度和起始地址，每次访问内存都判断地址是否在这个范围内。

![image-20221121194941478](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121194941478.png)

# 分段

`第十版教材中删掉了这部分内容`

将程序划分为多个段进行存储，例如堆栈段、程序段、数学库段。每个段可以不连续、大小可以不同。

## 地址转换

- 地址的表示通过<段号，偏移>的有序对表示。

- 分段通过段表(segment table)进行存储，段表的每个条目都有段基地址(segment base)和段界限(segment limit)两部分，分别表示起始位置和长度。

- 由MMU完成<段号，偏移>的逻辑地址到物理地址的转换。

  ![image-20221121201421945](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121201421945.png)

# 分页

将内存分为同样大小的块，称为帧或页帧(frame)，而逻辑内存也分为同样大小的块，称为页或页面(page)。每个页都可以分配到任意的帧上存储。这种方法灵活、寻址方便，还避免了外部碎片，是最常用的方法。

## 地址转换

- 页的大小为2的整数次幂，因此逻辑地址仍然用一个二进制数表示，但前一部分表示页码，后一部分表示页内偏移。

  ![image-20221121203016987](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121203016987.png)

- 用页表(page table)存储页码到物理地址的转换关系。页表的下标为页码，内容为该页在内存中的起始位置（如果在内存中）。每个进程都有自己独立的页表。

- 用帧表(frame table)存储内存的每个帧是否被占用、被哪个进程的哪一页占用。整个系统只有一个帧表。

- 由MMU将逻辑地址的页码转换为物理帧号，实现逻辑地址到物理地址的转换。

  ![image-20221121203239904](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121203239904.png)

## 页表存储

- 对于较小的页表，可以用专用寄存器存储。而对于很大的页表，只能将其存储在内存中。
- 页表基地址寄存器(Page-Table Base Register, PTBR)：用于指向页表在内存中的位置。这样，切换进程时只需要更改PTBR，而不是整个页表。
- 可以用页表长度寄存器(Page-Table Length Register, PTLR)来存储页表的长度，防止访问页表中不存在，即未定义的空间。
- 除页码和帧号外，页表的每一项还可以存储其他信息，如：可以用有效-无效位记录页是否为空，或是否被调入了内存。再比如，可以记录每个页是只读的还是可读写的。

## TLB

页表存储在内存中会导致每次内存读写都需要访问两次内存，解决方法是单独设立一个页表的高速缓存，称为转换表缓冲区(Translation Look-aside Buffer, TLB)。

![image-20221121210439999](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121210439999.png)

- 地址转换时首先访问TLB。TLB未命中(TLB miss)时，再访问页表，然后把得到的结果存入TLB。
- 若装入新条目时TLB已满，可以使用LRU等策略替换。
- 有的TLB允许固定下(wired down)特定条目，如内核关键代码的条目。
- TLB可以有两个(代码一个，数据一个)，但不可能做到一个进程一个。因此有的TLB还存储地址空间标识符(Address-Space Identifier, ASID)，即每一项所属的进程。这样做可以让多个进程共用TLB，以及提供进程间的内存保护。
- 对于不支持ASID的页表，切换进程时应该被整个刷新。

## 共享

对于可共享的数据或代码，可以通过让不同进程的页表映射到同一物理地址，实现共享访问。这样可以实现通用代码的共用、进程间通信等功能。

## 页表结构

- 分层分页(hierarchical paging)

  ![image-20221121213633192](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121213633192.png)

- 哈希页表(hashed page table)：可以用来将一个过大的页码空间映射到较小的空间，解决稀疏(sparse)页表占用空间过大的问题。

  ![image-20221121213855812](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121213855812.png)

- 倒置页表(inverted page table)：整个系统只使用一个页表，而不是一个进程一个。页表中只存储真正在物理内存中存在的页。地址变换时需要查找整张表，找到进程号和页码都匹配的项。可以使用哈希页表优化。

  ![image-20221121214914036](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121214914036.png)

# 虚拟内存

## 作用

虚拟内存的出现背景在于，程序运行时很多东西都是没有必要实际放入内存的，如：

- 很少执行的代码并不需要实际调入内存。
- 数组、链表等结构可能声明了很大的空间，却只使用一小部分，另一部分可以不用实际在内存中存储。

虚拟内存的作用就在于，让每个进程以为自己可以使用的内存空间依然是一整大块，而数据实际上在内存中可能是碎片化的、甚至根本就没有被载入内存，由操作系统在背后完成转换工作。这样做的好处包括：

- 程序员不再需要考虑实际的内存大小和分配方式，可以把内存当作一大块可以随意使用的连续空间。
- 没有必要的数据不会被放入内存，这使得系统能够同时运行更多程序。
- 不同进程共用的代码和数据可以不用单独存储，共用相同的页就可以了，这也节约了内存的开销。

## 实现

- 虚拟地址空间：基于分页式存储，采用页表、MMU将虚拟地址空间映射到实际地址。

- 请求调页(demand paging)：程序运行开始时不是将所有可能用到的页都调入，而是由操作系统预测会被使用的一部分调入。使用未调入内存的页时，发生缺页(page fault)，由操作系统将其从磁盘中读入内存。

  这种方法需要页表中使用有效-无效位来记录某一页是否已经被调入内存。

  ![image-20221121215835237](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121215835237.png)

- 页面置换：当内存不足时，不是选择将某个进程整个挂起，而是选择某一页，将其换出。

  可以使用修改位(modify bit, 或称脏位, dirty bit)存储每个页面是否较磁盘中的被修改过，置换页面时优先选择没有被修改过的，这样就不需要写回磁盘了。
  
  ![image-20221121220252067](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121220252067.png)

# 虚拟内存算法

## 页面置换算法

需要置换页面时，选择牺牲哪个页面的算法。目标是缺页次数越少越好。需要注意Belady异常(Belady's anomaly)的问题：帧数增加，缺页次数反而增加。

- 最优页面置换(optimal page-replacement algorithm)：置换接下来最长时间不会被使用的页面。

  - 不会导致Belady异常
  - 是理论上可以达到的最高效的算法，但是由于无法预知进程未来的调用序列，该算法无法实现

- FIFO(First-In-First-Out)：置换最早被调入内存的帧。

  - 可能导致Belady异常

- LRU(Least-Recent-Used)：置换最长时间没有被使用的页。这种算法的思想是利用过去的信息对未来做预估，长时间没有被使用的页面将来也大概率不会被使用。

  - 不会导致Belady异常
  - 实现方式1：计数器/时钟，即为每个页表条目增加其上次使用持续/时间的存储，但每次换页都要搜索
  - 实现方式2：使用堆栈存储页面的调用顺序，最近被访问的放置在栈顶，最长时间未被访问的放置在栈底。这种方法不需要搜索，但需要大量改动堆栈中的指针

- 近似LRU：内存中每个页都用一个移位寄存器记录使用情况，页被使用时将寄存器的最高位置1，同时周期性的将所有页面的寄存器右移一位，这样寄存器值最小的就是最久未使用的页（可能不唯一）。

- 第二次机会页面置换算法(second-chance page-replacement algotithm，也叫做时钟算法，clock algorithm)：可以看做是FIFO和近似LRU的结合。

  - 系统存储一个按调入内存的顺序排序的页面队列，以及每个页面是否最近被调用过的引用位，每次调用都会将该位置1。
  - 需要置换时系统从队首开始，遇到引用位为1的则将其引用位置0，移到队尾，遇到引用位为0的则将其置换。可以理解为是，引用位的1相当于一个一次性的“免死金牌”。
  - 该方法在FIFO的基础上保证了最近经常被访问的页不会被置换出。

  ![image-20221121154248539](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221121154248539.png)

- 其他算法：

  - 增强型二次机会算法：在第二次机会算法的基础上改进而来，将判断引用位改为了判断（引用位、修改位）的组合。
  - 最不经常使用(Least Frequently Used, LFU)
  - 最经常使用(Most Frequently Used, MFU)：这种算法有时候也是有用的，思想在于最近被调入但还没有怎么被使用的页可能马上就会被使用。

## 帧的分配算法

处理在多进程系统中，为每个进程分配多少个帧、发生缺页时置换哪个进程的帧等问题。

- 最小帧数：根据机器使用的指令集，单个指令可能需要同时调用多个页，这决定了单个进程最少需要的帧数。如：一个移动指令可能指令横跨两页，数据来源横跨两页，数据目的地址横跨两页，共需要六页。
- 平均分配(equal allocation)和比例分配(proportional allocation)（按虚拟内存的大小比例）。
- 全局置换(global replacement)和局部置换(local replacement)，即是否允许进程缺页时牺牲其他较低优先级进程的帧。
- 对于非均匀内存访问(Non-Uniform Memory Access, NUMA)系统，即具有多个CPU和内存的系统，为进程页面分配帧时，帧所处的内存应该尽可能靠近执行进程的CPU。

# 虚拟内存优化

## 系统抖动

抖动(Thrashing)：指由于给进程分配的帧不足，而导致频繁缺页的情况。抖动可能出现恶性循环：进程长时间等待换页，CPU利用率降低，此时调度程序开始更多程序的运行以提高CPU利用率，单个进程的可用帧数更加减少。因此普通的调度方案不能解决抖动问题。

- 工作集模型(working-set model)：基于局部性假设，根据进程最近调用的$\Delta$个页的集合中页的个数，为进程分配帧数。
- 缺页错误频率(Page-Fault Frequency, PFF)：设定缺页频率的上下限，高于上限时为进程分配更多的帧，低于下限时减少进程的可用帧。

## 写时复制

写时复制(copy-on-write)：使用fork()创建新进程时子进程可以直接与父进程共用相同的页，要修改哪个页的时候再复制对应的页。

## 内存映射

进程使用标准系统调用open()、read()、write()来访问磁盘文件时，可以采用内存映射(memory mapping)的方法，将磁盘文件映射到进程的虚拟内存空间。

- 进程访问文件，等同于访问自己的虚拟内存，页并不实际存在于内存中时将其调入。
- 修改文件时先修改内存，页被调出时再将修改写回磁盘。
- 多个进程打开同一个文件时，这些进程的虚拟内存页指向物理内存的同一帧，该帧存储了磁盘上该文件的拷贝。可以使用写时复制的方法使得进程修改文件时生成独立的副本，不影响原文件。

除了对文件的操作，对外部设备的I/O、数据传输等操作也都可以进行内存映射，例如，为显示器映射一块内存，显示文本就等同于在这块内存中写入数据。

## 内核内存

内核对内存分配的要求不同于普通进程：

- 内核有大量不足一页的数据结构，如果都按页分配内存会产生大量的内部碎片
- 有些硬件直接与物理内存交互，不经过虚拟内存，因此这部分的内存应该连续地常驻于内存的某个固定位置

解决内核内存分配问题的方法包括：

- 伙伴系统(buddy system)：将一块连续的内存分为2的整数次幂大小的块，每种大小的块单独存储，如系统为1KB、2KB、4KB等大小的块分别建立链表用于记录。

  分配内存时，找到一块大小最接近的内存块，没有则从更大的块中分离出来。例如对于一块256KB大小的内存，需要分配一个21KB的块，则系统首先将256KB分为两个128KB的块，再取一个128KB的块分解为两个64KB的块，最后得到32KB的块。

  内存释放时执行逆过程，将较小的合并(coalesce)为更大的块。

  ![image-20221123142101987](media/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20221123142101987.png)

- slab分配：在伙伴分配器的基础上进一步细分。思路是，为每一种内核数据结构，如信号量、进程描述符等分配一个cache。每个cache由若干个slab组成。每个slab对应内存中若干个连续的页面，按照所存储的数据结构类型分为相同大小的块。

  这种分配方式的好处在于，对于每种数据结构，所处的位置都是已经分配好的。当这个数据结创建新的实例对象时可以随用随取，实例对象使用结束后将该块标记为空闲即可，内存不会被收回。这样便提高了分配速度，避免了内部碎片。

## 其他优化

- 页面缓冲：系统保留一个空闲帧缓冲池，使得发生缺页时有空闲帧可以立即使用，原有帧的置换可以留到后面再慢慢执行。
- 原始磁盘(raw disk)：某些应用，如数据库，比操作系统更能理解自己应该怎么分配存储，怎么缓存数据，操作系统中文件系统的介入反而会降低他们的速度。因此有些操作系统允许应用绕过文件系统，直接操纵磁盘分区。
- 增大TLB范围(TLB reach)，即可以通过TLB直接访问的内存大小，方法包括扩大TLB、提供更大的页。
- 倒置页表和普通页表结合，即一般情况下使用倒置页表，出现缺页时才将普通页表调入内存。
- 允许页面被锁定到内存中，从而避免正在进行I/O的页被换出、或低优先级进程所需的页好不容易被换入了，还没使用就又被高优先级进程换走的情况。
