# 主定理

**Master Theorem**
$$
T(n)= \begin{cases}\Theta(1), & \text { if } n=1, \\ a T(n / b)+f(n), & \text { if } n>1 .\end{cases}
$$
where $a \geq 1, b>1$ are constants and $f$ is nonnegative. Then
1. If $f(n)=O\left(n^{\log _b a-\varepsilon}\right)$ for some constant $\varepsilon>0$, then $T(n)=\Theta\left(n^{\log _b a}\right)$.
2. If $f(n)=\Theta\left(n^{\log _b a}\right)$, then $T(n)=\Theta\left(n^{\log _b a} \log n\right)$.
3. If $f(n)=\Omega\left(n^{\log _b a+\varepsilon}\right)$ for some constant $\varepsilon>0$, and if $a f(n / b) \leq c f(n)$ for some constant $c<1$ and all sufficiently large $n$, then $T(n)=\Theta(f(n))$.

# 理解

![img](media/%E4%B8%BB%E5%AE%9A%E7%90%86/20200606181618820_5907.png)

一个分治算法所需的时间可以分为两部分：分治后最底层每个叶子结点所需的时间，以及每次分治所需的时间。

树的高度为$\log_{b}n$，故叶子的数目为$a^{\log _b n}=n^{\log _b a}$。计算单个叶子所需的时间为$\Theta(1)$，故计算叶子所需的总的时间为$\Theta(n^{\log_{b}a})$。

分治并合并的函数为$f(n)$，分治所需的总时间为$g(n)=\sum_{j=0}^{\log _b n-1} a^j f\left(\frac{n}{b^j}\right)$。

主定理所要做的就是比较这两部分的阶的大小，从而得到整个算法的时间复杂度。

# 证明

证明的关键就是要求出$g(n)=\sum_{j=0}^{\log _b n-1} a^j f\left(\frac{n}{b^j}\right)$的阶的大小，分为以下三种情况进行分析：

1. $f(n)=O\left(n^{\log _b a-\varepsilon}\right) $，即$f(n)$的阶小于$n^{\log_{b}a}$的情况，有
   $$
   \begin{aligned}
   g(n) &= O \left(\sum_{j=0}^{\log _b n-1} a^j\left(\frac{n}{b^j}\right)^{\left(\log _b a\right)-\epsilon}\right) \\
   &= O \left(\sum_{j=0}^{\log _b n-1} a^j\frac{n^{\left(\log _b a\right)-\epsilon}}{b^{j\left[\left(\log _b a\right)-\epsilon\right]}}\right)\\
   &= O \left(\sum_{j=0}^{\log _b n-1} n^{\left(\log _b a\right)-\epsilon}\frac{a^j}{b^{j\left[\left(\log _b a\right)-\epsilon\right]}}\right)\\
   &= O \left(n^{\left(\log _b a\right)-\epsilon} \sum_{j=0}^{\log _b n-1}\left(\frac{a}{b^{\left(\log _b a\right)-\epsilon}}\right)^j\right) \\
   &= O \left(n^{\left(\log _b a\right)-\epsilon} \sum_{j=0}^{\log _b n-1}\left(\frac{a b^\epsilon}{a}\right)^j\right) \\
   &= O \left(n^{\left(\log _b a\right)-\epsilon} \sum_{j=0}^{\log _b n-1}\left(b^\epsilon\right)^j\right) \\
   &= O \left(n^{\left(\log _b a\right)-\epsilon} \frac{b^{\epsilon \log _b n}-1}{b^{\epsilon}-1}\right) \\
   &= O \left(n^{\left(\log _b a\right)-\epsilon} \frac{n^{\epsilon}-1}{b^{\epsilon}-1}\right)
   \end{aligned}
   $$
   $\epsilon,b$都是常数，所以$g(n)=O \left( n^{\log _b a}\right)$。

2. $f(n)=\Theta\left(n^{\log _b a}\right)$，即$f(n)$的阶等于$n^{\log_{b}a}$的情况，有
   $$
   \begin{aligned}
   g(n) &=\Theta\left(\sum_{j=0}^{\log _b n-1} a^j\left(\frac{n}{b^j}\right)^{\log _b a}\right) \\
   &=\Theta\left(\sum_{j=0}^{\log _b n-1} a^j \left(\frac{n^{\log _b a}}{b^{j\log _b a}}\right)\right)\\
   &=\Theta\left(n^{\log _b a} \sum_{j=0}^{\log _b n-1}\left(\frac{a^j}{b^{j\log _b a}}\right)\right) \\
   &=\Theta\left(n^{\log _b a} \sum_{j=0}^{\log _b n-1}\left(\frac{a}{b^{\log _b a}}\right)^j\right) \\
   &=\Theta\left(n^{\log _b a} \sum_{j=0}^{\log _b n-1} 1\right) \\
   &=\Theta\left(n^{\log _b a} \log _b n\right) \\
   &=\Theta\left(n^{\log _b a} \log _2 n\right)
   \end{aligned}
   $$

3. $f(n)=\Omega\left(n^{\left(\log _b a\right)+\epsilon}\right)$，即$f(n)$的阶大于$n^{\log_{b}a}$的情况，首先注意到这个奇怪的条件：$a f(n / b) \leq c f(n),0<c<1$。直观地研究这个式子，含义可以理解为是在递归树中，$f(n)$函数下一层所用的时间，阶数应该小于上一层。

   这个式子的用处在于，递归使用这个式子，能够得到$a^j f\left(\frac{n}{b^j}\right) \leq c^j f(n)$，可以用来将$f(n/b^i)$转化为$f(n)$，代回$g(n)$的表达式就能得到：
   $$
   \begin{aligned}
   g(n) &= \sum_{j=0}^{\log _b n-1} a^j f\left(\frac{n}{b^j}\right) \\
   & \leq \sum_{j=0}^{\log _b n-1} c^jf(n) \\
   & \leq f(n)\sum_{j=0}^{\infty} c^j \\
   & = f(n) \cdot \frac{1}{1-c} \\
   & = O(f(n))
   \end{aligned}
   $$

这样，三种情况下$g(n)$的时间复杂度都已经分析完毕，稍加整理即可得到主定理了。